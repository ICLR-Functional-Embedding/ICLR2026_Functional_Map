{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee79d1d4",
   "metadata": {},
   "source": [
    "# Description: \n",
    "This notebook contains the functional embedding being trained on multiple subjetcs' real recordings using PSC and MSC methods and how it generalizes over held out time segments and held out channels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd25ca4",
   "metadata": {},
   "source": [
    "# Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.io import loadmat\n",
    "import plotly.io as pio\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local libraries\n",
    "from src.tools.simulation import *\n",
    "from src.models.CNN_encoder import *\n",
    "from src.signal.signal_processing import *\n",
    "from src.pipelines.embedding_data_preparation import *\n",
    "from src.utils.utils import *\n",
    "from src.training.PSC_training import *\n",
    "from src.training.visualize_embedding import *\n",
    "from src.training.evaluation import *\n",
    "from src.training.MSC_training import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8abbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset related libraries (have to replace these with your own dataset loading functions), replace with your own dataset source files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "directory_path = \"D:/Python Projects/ICLR 2026/Dataset_Related\"\n",
    "sys.path.append(os.path.abspath(directory_path))\n",
    "from dataset import *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19a9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset related functions and mappings\n",
    "# These functions should be customized for each subject and dataset, here example functions are provided\n",
    "\n",
    "\n",
    "# Define which subjects and sessions to use. subjects are keys and sessions are values\n",
    "# subject_sessions = {\n",
    "#     's1': ['p1'], \n",
    "#     's2': ['p1'], \n",
    "#     's3': ['p4', 'p6'], \n",
    "#     's4': ['p1', 'p2'],\n",
    "#     's5': ['p1', 'p2', 'p3', 'p6', 'p7'],\n",
    "#     's6': ['p1', 'p2'], \n",
    "#     's7': ['p1'], \n",
    "#     's8': ['p9'],\n",
    "#     's9': ['p1', 'p2', 'p3'], \n",
    "#     's10': ['p6', 'p7', 'p8', 'p9'],\n",
    "# }\n",
    "\n",
    "# def get_true_region(subject, electrode_name, side, electrode_number, verbose=False):\n",
    "#     \"\"\"\n",
    "#     This function defines the mapping from electrode name and contact number to true brain region for a given subject.\n",
    "#     \"\"\"\n",
    "#     if verbose: print(f\"using default arrangement for {subject}\")\n",
    "#     if 'GPi'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'GPi'\n",
    "#     elif 'VPLa'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VPla'\n",
    "#     elif 'VoSTN'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VO'\n",
    "#     elif 'VoSTN'.lower() in electrode_name.lower() and electrode_number in [1,2,3]:\n",
    "#         return 'STN'\n",
    "#     elif 'STN'.lower() in electrode_name.lower() and electrode_number in [4,5,6]: \n",
    "#         return 'STN'\n",
    "#     elif 'VIM'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VIM'\n",
    "#     elif 'PPN'.lower() in electrode_name.lower() and electrode_number in [1,2,3]:\n",
    "#         return 'PPN'\n",
    "#     elif 'VA'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VA'\n",
    "#     elif 'VoaVop'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VoaVop'\n",
    "#     elif 'VoaVop'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VoaVop'\n",
    "#     else: \n",
    "#         return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3922e42b",
   "metadata": {},
   "source": [
    "# Training functional encoder on aggregated dataset including several subjects and sessions Using PSC method\n",
    "This sections creates a new dataset and adds all recording sessions and trains and evaluates a functional encoder on that dataset, using held out times (test dataset) and held out channels for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb888e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "device = get_device()\n",
    "print(f\" Using {device}\")\n",
    "\n",
    "# ----------- Config ------------ \n",
    "# training parameters\n",
    "EPOCHS = 1\n",
    "DATASET_SIZE = 1000000\n",
    "LEARNING_RATE = 1e-2\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# model parameters\n",
    "EMBEDDING_DIM = 32\n",
    "VERSION = \"v1(PSC)\"\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# data preparation \n",
    "SEGMENT_LENGTH = 10000 # in ms here is 10 seconds\n",
    "MIN_SEGMENTS_PER_SESSION = 10 # skip sessions with too few segments\n",
    "\n",
    "\n",
    "# visualization\n",
    "show_model = True\n",
    "#--------------------------------\n",
    "\n",
    "\n",
    "dataPath = \"D:\\\\transfer\\\\micro voluntary dataset\\\\lfs data\" # path to data folder (replace with your own data path)\n",
    "experiment = \"Multi session training\" \n",
    "subject_counter = 0\n",
    "\n",
    "training_segments_dict = {}\n",
    "validation_segments_dict = {}\n",
    "testing_segments_dict = {}\n",
    "held_out_channels_dict = {}\n",
    "\n",
    "for isubject in subject_sessions.keys():\n",
    "    subject_counter += 1\n",
    "    for iperiod in subject_sessions[isubject]:\n",
    "        print(\"Loading data from subject: S\" + str(subject_counter) + \" period: \" + iperiod)\n",
    "        # load microelectrode labels which contains the names of all microelectrodes in this session\n",
    "        micro_electrode_path = dataPath  + os.sep + isubject + os.sep + iperiod + os.sep\n",
    "        try:\n",
    "            microelectrodes = load_micro_labels(micro_electrode_path + \"microLabels.mat\")\n",
    "        except:\n",
    "            mat_contents = loadmat(micro_electrode_path + \"microLabels.mat\")\n",
    "            micro_labels = mat_contents['microLabels'] \n",
    "            microelectrodes = [str(label[0]) if isinstance(label, np.ndarray) else str(label) for label in micro_labels.squeeze()]\n",
    "\n",
    "        \n",
    "        region_electrode_count = {}\n",
    "        hold_out_check = 4 # holds 1 channel out every n channels\n",
    "\n",
    "        # Parse and print them\n",
    "        for microelectrode in microelectrodes:\n",
    "            region, side, electrode = parse_label(microelectrode)\n",
    "\n",
    "            # get true region of this electrode\n",
    "            true_region = get_true_region(isubject, region, side, electrode)\n",
    "            if true_region != 'unknown':\n",
    "                print(f\"Loading {microelectrode} --> Region: {region}, Side: {side}, Electrode: {electrode} true region: {true_region}\")\n",
    "\n",
    "                # load data\n",
    "                mat_path = os.path.join(micro_electrode_path, microelectrode + \".mat\")\n",
    "                raw_signal = None \n",
    "                try:\n",
    "                    # First try HDF5 (MATLAB v7.3 format)\n",
    "                    with h5py.File(mat_path, \"r\") as f:\n",
    "                        raw_signal = np.array(f[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"⚠️ File not found: {mat_path}. Skipping electrode.\")\n",
    "                    continue  # Skip to next electrode\n",
    "                except (OSError, KeyError):\n",
    "                    # Fall back to standard .mat format (pre-v7.3)\n",
    "                    try:\n",
    "                        mat = scipy.io.loadmat(mat_path)\n",
    "                        raw_signal = np.array(mat[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(mat[\"fs\"]).squeeze())\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Failed to load (not a valid .mat file): {mat_path}. Error: {e}\")\n",
    "                        continue  # Skip if even fallback fails\n",
    "\n",
    "                # Remove big 60Hz artifacts\n",
    "                filtered_signal = notch_filter(raw_signal,fs)\n",
    "\n",
    "                # Normalize session recording\n",
    "                normalized_signal = normalize_signal(filtered_signal)\n",
    "\n",
    "                # Apply notch filters at 60Hz and its harmonics\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=60)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=120)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=180)\n",
    "\n",
    "                # Segment data into windows\n",
    "                signal_segments = segment_data(normalized_signal, SEGMENT_LENGTH)\n",
    "\n",
    "                # Skip sessions with too few segments\n",
    "                if len(signal_segments) < MIN_SEGMENTS_PER_SESSION:\n",
    "                    print(\"session too short\")\n",
    "                    continue\n",
    "\n",
    "                # Check if this region already has 3 electrodes, add this channel to held out channels\n",
    "                region_electrode_count[true_region] = region_electrode_count.get(true_region ,0) + 1\n",
    "                if region_electrode_count[true_region] % hold_out_check ==0:\n",
    "                    # add to held out channel dictionary\n",
    "                    if true_region in held_out_channels_dict:\n",
    "                        held_out_channels_dict[true_region] = np.concat([held_out_channels_dict[true_region], signal_segments])\n",
    "                    else:\n",
    "                        held_out_channels_dict[true_region] = signal_segments\n",
    "                else: \n",
    "                    # Split segments into training, validation, and testing sets\n",
    "                    num_val = int(0.15 * len(signal_segments))\n",
    "                    num_test = int(0.15 * len(signal_segments))\n",
    "                    val_segments = signal_segments[:num_val]\n",
    "                    test_segments = signal_segments[num_val:num_val+num_test]\n",
    "                    train_segments = signal_segments[num_val+num_test:]\n",
    "\n",
    "                    # add to training dictionary\n",
    "                    if true_region in training_segments_dict:\n",
    "                        training_segments_dict[true_region] = np.concat([training_segments_dict[true_region], train_segments])\n",
    "                    else:\n",
    "                        training_segments_dict[true_region] = train_segments\n",
    "\n",
    "                    # add to validation dictionary\n",
    "                    if true_region in validation_segments_dict:\n",
    "                        validation_segments_dict[true_region] = np.concat([validation_segments_dict[true_region], val_segments])\n",
    "                    else:\n",
    "                        validation_segments_dict[true_region] = val_segments\n",
    "\n",
    "                    # add to testing dictionary\n",
    "                    if true_region in testing_segments_dict:\n",
    "                        testing_segments_dict[true_region] = np.concat([testing_segments_dict[true_region], test_segments])\n",
    "                    else:\n",
    "                        testing_segments_dict[true_region] = test_segments\n",
    "\n",
    "        # print held out channels\n",
    "        print(\"held out channels : \", region_electrode_count)\n",
    "\n",
    "\n",
    "# Shuffle segments within each region key before training\n",
    "print(\"Shuffle segments...\")\n",
    "for d in [training_segments_dict, validation_segments_dict, testing_segments_dict, held_out_channels_dict]:\n",
    "    for k in d:\n",
    "        np.random.shuffle(d[k])\n",
    "\n",
    "# save datasets\n",
    "save_path = os.path.join(\"data\",\"multi_subject_functional_encoder_training\",\"data_splits\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(os.path.join(save_path, \"training_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(training_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"validation_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(validation_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"testing_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(testing_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"heldout_channels.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(held_out_channels_dict, f)\n",
    "\n",
    "\n",
    "# Generate training and validation pairs for the Pairwise Siamese Contrastive (PSC) method\n",
    "print(\"Generating training and validation pairs...\")\n",
    "train_pairs, train_labels = create_balanced_pairs(training_segments_dict, DATASET_SIZE)\n",
    "val_pairs, val_labels = create_balanced_pairs(validation_segments_dict, min(int(0.2 * DATASET_SIZE),20000))\n",
    "\n",
    "# Create DataLoaders\n",
    "train_ds = LFPDataset(train_pairs, train_labels)\n",
    "val_ds = LFPDataset(val_pairs, val_labels)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "print(f\"Train set: {len(train_ds)} pairs\")\n",
    "print(f\"Validation set: {len(val_ds)} pairs\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# Print shapes for sanity check\n",
    "print(\"===== Training Input Shape Info =====\")\n",
    "for x1, x2, _ in train_loader:\n",
    "    print(f\"Train input shapes: x1: {x1.shape}, x2: {x2.shape}\")\n",
    "    break\n",
    "print(\"===== Validation Input Shape Info =====\")\n",
    "for x1, x2, _ in val_loader:\n",
    "    print(f\"Validation input shapes: x1: {x1.shape}, x2: {x2.shape}\\n\\n\")\n",
    "    break\n",
    "\n",
    "# Model setup\n",
    "print(\"Training model...\")\n",
    "model = SiameseNetMultiSubject(embedding_dim=EMBEDDING_DIM,dropout=DROPOUT, normalized_output=True).to(device)\n",
    "if show_model:\n",
    "    print_model_summary(model, train_loader, device)\n",
    "    show_model = False\n",
    "\n",
    "# train model\n",
    "save_path = os.path.join(\"results\",\"multi_subject_functional_encoder\",\"PSC_model\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "trained_model = training_validate_loop(model, train_loader, val_loader, device, save_path, EPOCHS, LEARNING_RATE)\n",
    "\n",
    "# Extract encoder and evaluate\n",
    "trained_model.eval()\n",
    "encoder_model = trained_model.encoder\n",
    "encoder_model.eval()\n",
    "\n",
    "# Extract embeddings\n",
    "print(\"Extracting embeddings...\")\n",
    "train_emb, train_labels_text = embed_segments_dict(training_segments_dict, encoder_model, device)\n",
    "val_emb, val_labels_text = embed_segments_dict(validation_segments_dict, encoder_model, device)\n",
    "test_emb, test_labels_text = embed_segments_dict(testing_segments_dict, encoder_model, device)\n",
    "held_emb, held_labels_text = embed_segments_dict(held_out_channels_dict, encoder_model, device)\n",
    "\n",
    "# KNN Evaluation\n",
    "print(\"Extracting embeddings...\")\n",
    "for k in training_segments_dict:\n",
    "    print(f\"{k}: {len(training_segments_dict[k])} segments\")\n",
    "\n",
    "# make region balanced reference set for knn\n",
    "ref_emb, ref_labels = make_balanced_reference(train_emb, train_labels_text, per_class=None, seed=42)\n",
    "results_train = evaluate_knn(ref_emb, ref_labels, train_emb, train_labels_text)\n",
    "results_val = evaluate_knn(ref_emb, ref_labels, val_emb, val_labels_text)\n",
    "results_test = evaluate_knn(ref_emb, ref_labels, test_emb, test_labels_text)\n",
    "results_held = evaluate_knn(ref_emb, ref_labels, held_emb, held_labels_text)\n",
    "\n",
    "# Chance & clustering\n",
    "print (\"Computing clustering metrics...\")\n",
    "chance_train = compute_chance_levels(train_labels_text)\n",
    "chance_val = compute_chance_levels(val_labels_text)\n",
    "chance_test = compute_chance_levels(test_labels_text)    \n",
    "chance_held = compute_chance_levels(held_labels_text)\n",
    "\n",
    "metrics_train = evaluate_clustering_metrics(train_emb, train_labels_text)\n",
    "metrics_val = evaluate_clustering_metrics(val_emb, val_labels_text)\n",
    "metrics_test = evaluate_clustering_metrics(test_emb, test_labels_text)\n",
    "metrics_held = evaluate_clustering_metrics(held_emb, held_labels_text)\n",
    "\n",
    "# Save confusion matrix \n",
    "print(\"Generating and saving confusion matrices...\")\n",
    "plot_and_save_confusion_matrix(val_labels_text, results_val['predictions'], sorted(set(val_labels_text)), \"Validation Confusion\", os.path.join(save_path, \"cm_val.png\"))\n",
    "plot_and_save_confusion_matrix(test_labels_text, results_test['predictions'], sorted(set(test_labels_text)), \"Test Confusion\", os.path.join(save_path, \"cm_test.png\"))\n",
    "plot_and_save_confusion_matrix(held_labels_text, results_held['predictions'], sorted(set(held_labels_text)), \"Held-Out Subject Confusion\", os.path.join(save_path, \"cm_heldout.png\"))\n",
    "\n",
    "# Embedding visualization\n",
    "test_region_list = [label for label in test_labels_text]\n",
    "test_side_list = [\"\" for _ in test_labels_text]\n",
    "test_electrode_list = [\"\"] * len(test_labels_text)\n",
    "fig,_ = plot_interactive_embeddings(test_emb, test_region_list, test_electrode_list, test_side_list, dim=2, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_testset_pca_2D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_testset_pca_2D.json\"), pretty=True)\n",
    "\n",
    "fig,_ = plot_interactive_embeddings(test_emb, test_region_list, test_electrode_list, test_side_list, dim=3, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_testset_pca_3D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_testset_pca_3D.json\"), pretty=True)\n",
    "has_heldout = any(len(v) > 0 for v in held_out_channels_dict.values())\n",
    "\n",
    "held_out_region_list = [label for label in held_labels_text]\n",
    "held_out_side_list = [\"\" for _ in held_labels_text]\n",
    "held_out_electrode_list = [\"\"] * len(held_labels_text)\n",
    "fig,_ = plot_interactive_embeddings(held_emb, held_out_region_list, held_out_electrode_list, held_out_side_list, dim=3, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_heldout_pca_3D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_heldout_pca_3D.json\"), pretty=True)\n",
    "\n",
    "\n",
    "# Save results\n",
    "save_evaluation_to_excel(\n",
    "    subject_id=\"Multi-subject training\",\n",
    "    model_name=VERSION,\n",
    "    results_train=results_train,\n",
    "    results_test=results_test,\n",
    "    results_heldout=results_held,\n",
    "    clustering_train=metrics_train,\n",
    "    clustering_test=metrics_test,\n",
    "    clustering_heldout=metrics_held,\n",
    "    chance_train=chance_train,\n",
    "    chance_test=chance_test,\n",
    "    chance_heldout=chance_held,\n",
    "    save_path=os.path.join(\"results\",\"multi_subject_functional_encoder\" , \"evaluation_summary_multi_subject.xlsx\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221cd437",
   "metadata": {},
   "source": [
    "# Training functional encoder on aggregated dataset including several subjects and sessions Using MSC method\n",
    "This sections creates a new dataset and adds all recording sessions and trains and evaluates a functional encoder on that dataset, using held out times (test dataset) and held out channels for evaluation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a2ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "device = get_device()\n",
    "print(f\" Using {device}\")\n",
    "\n",
    "# ----------- Config ------------ \n",
    "# training parameters\n",
    "EPOCHS = 200\n",
    "DATASET_SIZE = 1000000\n",
    "LEARNING_RATE = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "TEMPERATURE = 0.2\n",
    "\n",
    "# model parameters\n",
    "EMBEDDING_DIM = 32\n",
    "PROJ_DIM = 32\n",
    "VERSION = \"v1(MSC)\"\n",
    "DROPOUT = 0.35\n",
    "RANDOM_SEED=42\n",
    "\n",
    "# data preparation \n",
    "SEGMENT_LENGTH = 10000 # in ms here is 10 seconds\n",
    "MIN_SEGMENTS_PER_SESSION = 10 # skip sessions with too few segments\n",
    "\n",
    "# visualization\n",
    "show_model = True\n",
    "#--------------------------------\n",
    "\n",
    "\n",
    "dataPath = \"D:\\\\transfer\\\\micro voluntary dataset\\\\lfs data\" # path to data folder (replace with your own data path)\n",
    "experiment = \"Multi session training\" \n",
    "subject_counter = 0\n",
    "\n",
    "training_segments_dict = {}\n",
    "validation_segments_dict = {}\n",
    "testing_segments_dict = {}\n",
    "held_out_channels_dict = {}\n",
    "\n",
    "for isubject in subject_sessions.keys():\n",
    "    subject_counter += 1\n",
    "    for iperiod in subject_sessions[isubject]:\n",
    "        print(\"Loading data from subject: S\" + str(subject_counter) + \" period: \" + iperiod)\n",
    "        # load microelectrode labels which contains the names of all microelectrodes in this session\n",
    "        micro_electrode_path = dataPath  + os.sep + isubject + os.sep + iperiod + os.sep\n",
    "        try:\n",
    "            microelectrodes = load_micro_labels(micro_electrode_path + \"microLabels.mat\")\n",
    "        except:\n",
    "            mat_contents = loadmat(micro_electrode_path + \"microLabels.mat\")\n",
    "            micro_labels = mat_contents['microLabels'] \n",
    "            microelectrodes = [str(label[0]) if isinstance(label, np.ndarray) else str(label) for label in micro_labels.squeeze()]\n",
    "\n",
    "        \n",
    "        region_electrode_count = {}\n",
    "        hold_out_check = 4 # holds 1 channel out every N channels\n",
    "\n",
    "        # Parse and print them\n",
    "        for microelectrode in microelectrodes:\n",
    "            region, side, electrode = parse_label(microelectrode)\n",
    "\n",
    "            # get true region of this electrode\n",
    "            true_region = get_true_region(isubject, region, side, electrode)\n",
    "            if true_region != 'unknown':\n",
    "                print(f\"Loading {microelectrode} --> Region: {region}, Side: {side}, Electrode: {electrode} true region: {true_region}\")\n",
    "\n",
    "                # load data\n",
    "                mat_path = os.path.join(micro_electrode_path, microelectrode + \".mat\")\n",
    "                raw_signal = None \n",
    "                try:\n",
    "                    # First try HDF5 (MATLAB v7.3 format)\n",
    "                    with h5py.File(mat_path, \"r\") as f:\n",
    "                        raw_signal = np.array(f[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"⚠️ File not found: {mat_path}. Skipping electrode.\")\n",
    "                    continue  # Skip to next electrode\n",
    "                except (OSError, KeyError):\n",
    "                    # Fall back to standard .mat format (pre-v7.3)\n",
    "                    try:\n",
    "                        mat = scipy.io.loadmat(mat_path)\n",
    "                        raw_signal = np.array(mat[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(mat[\"fs\"]).squeeze())\n",
    "                    except Exception as e:\n",
    "                        print(f\"⚠️ Failed to load (not a valid .mat file): {mat_path}. Error: {e}\")\n",
    "                        continue  # Skip if even fallback fails\n",
    "\n",
    "                # Remove big 60Hz artifacts\n",
    "                filtered_signal = notch_filter(raw_signal,fs)\n",
    "\n",
    "                # Normalize session recording\n",
    "                normalized_signal = normalize_signal(filtered_signal)\n",
    "\n",
    "                # Apply notch filters at 60Hz and its harmonics\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=60)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=120)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=180)\n",
    "\n",
    "                # Segment data into windows\n",
    "                signal_segments = segment_data(normalized_signal, SEGMENT_LENGTH)\n",
    "\n",
    "                # Skip sessions with too few segments\n",
    "                if len(signal_segments) < MIN_SEGMENTS_PER_SESSION:\n",
    "                    print(\"session too short\")\n",
    "                    continue\n",
    "\n",
    "                # Check if this region already has 3 electrodes, add this channel to held out channels\n",
    "                region_electrode_count[true_region] = region_electrode_count.get(true_region ,0) + 1\n",
    "                if region_electrode_count[true_region] % hold_out_check ==0:\n",
    "                    # add to held out channel dictionary\n",
    "                    if true_region in held_out_channels_dict:\n",
    "                        held_out_channels_dict[true_region] = np.concat([held_out_channels_dict[true_region], signal_segments])\n",
    "                    else:\n",
    "                        held_out_channels_dict[true_region] = signal_segments\n",
    "                else: \n",
    "                    # Split segments into training, validation, and testing sets\n",
    "                    num_val = int(0.15 * len(signal_segments))\n",
    "                    num_test = int(0.15 * len(signal_segments))\n",
    "                    val_segments = signal_segments[:num_val]\n",
    "                    test_segments = signal_segments[num_val:num_val+num_test]\n",
    "                    train_segments = signal_segments[num_val+num_test:]\n",
    "\n",
    "                    # add to training dictionary\n",
    "                    if true_region in training_segments_dict:\n",
    "                        training_segments_dict[true_region] = np.concat([training_segments_dict[true_region], train_segments])\n",
    "                    else:\n",
    "                        training_segments_dict[true_region] = train_segments\n",
    "\n",
    "                    # add to validation dictionary\n",
    "                    if true_region in validation_segments_dict:\n",
    "                        validation_segments_dict[true_region] = np.concat([validation_segments_dict[true_region], val_segments])\n",
    "                    else:\n",
    "                        validation_segments_dict[true_region] = val_segments\n",
    "\n",
    "                    # add to testing dictionary\n",
    "                    if true_region in testing_segments_dict:\n",
    "                        testing_segments_dict[true_region] = np.concat([testing_segments_dict[true_region], test_segments])\n",
    "                    else:\n",
    "                        testing_segments_dict[true_region] = test_segments\n",
    "\n",
    "        # print held out channels\n",
    "        print(\"held out channels : \", region_electrode_count)\n",
    "\n",
    "\n",
    "# Shuffle segments within each region key before training\n",
    "print(\"Shuffle segments...\")\n",
    "for d in [training_segments_dict, validation_segments_dict, testing_segments_dict, held_out_channels_dict]:\n",
    "    for k in d:\n",
    "        np.random.shuffle(d[k])\n",
    "\n",
    "# save datasets\n",
    "save_path = os.path.join(\"data\",\"multi_subject_functional_encoder_training\",\"data_splits\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "with open(os.path.join(save_path, \"training_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(training_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"validation_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(validation_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"testing_segments.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(testing_segments_dict, f)\n",
    "with open(os.path.join(save_path, \"heldout_channels.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(held_out_channels_dict, f)\n",
    "\n",
    "\n",
    "# Generate training and validation pairs for the Pairwise Siamese Contrastive (PSC) method\n",
    "print(\"Generating training and validation datasets...\")\n",
    "train_supcon_ds = SupConDataset(training_segments_dict, transform=zscore_transform)\n",
    "val_supcon_ds   = SupConDataset(validation_segments_dict, transform=zscore_transform)\n",
    "\n",
    "train_supcon_loader = DataLoader(train_supcon_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_supcon_loader   = DataLoader(val_supcon_ds,   batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "print(f\"Train set: {len(train_supcon_ds)} pairs\")\n",
    "print(f\"Validation set: {len(val_supcon_ds)} pairs\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "# --- keep  pair dataset for validation after each epoch to compare with PSC ---\n",
    "val_pairs, val_labels = create_balanced_pairs(validation_segments_dict, max_dataset_size=min(20000, len(val_supcon_ds)*2))\n",
    "val_pair_ds = LFPDataset(val_pairs, val_labels)\n",
    "val_pair_loader = DataLoader(val_pair_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "# Model setup\n",
    "print(\"Training model...\")\n",
    "model = SupConNetMultiSubject(embedding_dim=EMBEDDING_DIM, proj_dim=PROJ_DIM, dropout=DROPOUT).to(device)\n",
    "if show_model:\n",
    "    print_model_summary(model, train_supcon_loader, device)\n",
    "    show_model = False\n",
    "\n",
    "save_path = os.path.join(\"results\",\"multi_subject_functional_encoder\",\"MSC_model\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "trained_model = training_validate_loop_supcon(\n",
    "model, train_supcon_loader, val_pair_loader, device, save_path,\n",
    "epochs=EPOCHS, lr=LEARNING_RATE,             # lower LR\n",
    "temperature=TEMPERATURE,                    # a bit larger temp often helps early\n",
    "add_nn=True                        # disable NN positives on single-subject\n",
    ")\n",
    "\n",
    "\n",
    "# Extract encoder and evaluate\n",
    "trained_model.eval()\n",
    "encoder_model = trained_model.encoder\n",
    "encoder_model.eval()\n",
    "\n",
    "# Extract embeddings\n",
    "print(\"Extracting embeddings...\")\n",
    "train_emb, train_labels_text = embed_segments_dict(training_segments_dict, encoder_model, device)\n",
    "val_emb, val_labels_text = embed_segments_dict(validation_segments_dict, encoder_model, device)\n",
    "test_emb, test_labels_text = embed_segments_dict(testing_segments_dict, encoder_model, device)\n",
    "held_emb, held_labels_text = embed_segments_dict(held_out_channels_dict, encoder_model, device)\n",
    "\n",
    "# KNN Evaluation\n",
    "print(\"Extracting embeddings...\")\n",
    "for k in training_segments_dict:\n",
    "    print(f\"{k}: {len(training_segments_dict[k])} segments\")\n",
    "\n",
    "# make region balanced reference set for knn\n",
    "ref_emb, ref_labels = make_balanced_reference(train_emb, train_labels_text, per_class=None, seed=42)\n",
    "results_train = evaluate_knn(ref_emb, ref_labels, train_emb, train_labels_text)\n",
    "results_val = evaluate_knn(ref_emb, ref_labels, val_emb, val_labels_text)\n",
    "results_test = evaluate_knn(ref_emb, ref_labels, test_emb, test_labels_text)\n",
    "results_held = evaluate_knn(ref_emb, ref_labels, held_emb, held_labels_text)\n",
    "\n",
    "# Chance & clustering\n",
    "print (\"Computing clustering metrics...\")\n",
    "chance_train = compute_chance_levels(train_labels_text)\n",
    "chance_val = compute_chance_levels(val_labels_text)\n",
    "chance_test = compute_chance_levels(test_labels_text)    \n",
    "chance_held = compute_chance_levels(held_labels_text)\n",
    "\n",
    "metrics_train = evaluate_clustering_metrics(train_emb, train_labels_text)\n",
    "metrics_val = evaluate_clustering_metrics(val_emb, val_labels_text)\n",
    "metrics_test = evaluate_clustering_metrics(test_emb, test_labels_text)\n",
    "metrics_held = evaluate_clustering_metrics(held_emb, held_labels_text)\n",
    "\n",
    "# Save confusion matrix \n",
    "print(\"Generating and saving confusion matrices...\")\n",
    "plot_and_save_confusion_matrix(val_labels_text, results_val['predictions'], sorted(set(val_labels_text)), \"Validation Confusion\", os.path.join(save_path, \"cm_val.png\"))\n",
    "plot_and_save_confusion_matrix(test_labels_text, results_test['predictions'], sorted(set(test_labels_text)), \"Test Confusion\", os.path.join(save_path, \"cm_test.png\"))\n",
    "plot_and_save_confusion_matrix(held_labels_text, results_held['predictions'], sorted(set(held_labels_text)), \"Held-Out channel Confusion\", os.path.join(save_path, \"cm_heldout.png\"))\n",
    "\n",
    "# Embedding visualization\n",
    "test_region_list = [label for label in test_labels_text]\n",
    "test_side_list = [\"\" for _ in test_labels_text]\n",
    "test_electrode_list = [\"\"] * len(test_labels_text)\n",
    "fig,_ = plot_interactive_embeddings(test_emb, test_region_list, test_electrode_list, test_side_list, dim=2, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_testset_pca_2D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_testset_pca_2D.json\"), pretty=True)\n",
    "\n",
    "fig,_ = plot_interactive_embeddings(test_emb, test_region_list, test_electrode_list, test_side_list, dim=3, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_testset_pca_3D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_testset_pca_3D.json\"), pretty=True)\n",
    "has_heldout = any(len(v) > 0 for v in held_out_channels_dict.values())\n",
    "\n",
    "held_out_region_list = [label for label in held_labels_text]\n",
    "held_out_side_list = [\"\" for _ in held_labels_text]\n",
    "held_out_electrode_list = [\"\"] * len(held_labels_text)\n",
    "fig,_ = plot_interactive_embeddings(held_emb, held_out_region_list, held_out_electrode_list, held_out_side_list, dim=3, method='pca', metric='euclidean', show_ellipses=True, verbose=False)\n",
    "pio.write_image(fig, os.path.join(save_path, f\"embedding_heldout_pca_3D.png\"), format=\"png\", width=950, height=700)\n",
    "pio.write_json(fig,  os.path.join(save_path, f\"embedding_heldout_pca_3D.json\"), pretty=True)\n",
    "\n",
    "\n",
    "# Save results\n",
    "save_evaluation_to_excel(\n",
    "    subject_id=\"Multi-subject training\",\n",
    "    model_name=VERSION,\n",
    "    results_train=results_train,\n",
    "    results_test=results_test,\n",
    "    results_heldout=results_held,\n",
    "    clustering_train=metrics_train,\n",
    "    clustering_test=metrics_test,\n",
    "    clustering_heldout=metrics_held,\n",
    "    chance_train=chance_train,\n",
    "    chance_test=chance_test,\n",
    "    chance_heldout=chance_held,\n",
    "    save_path=os.path.join(\"results\",\"multi_subject_functional_encoder\" , \"evaluation_summary_multi_subject.xlsx\")\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anonymized-ICLR2026.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
