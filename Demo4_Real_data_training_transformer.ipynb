{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cce2266",
   "metadata": {},
   "source": [
    "# Descrition: \n",
    "This notebook contains the transformer being trained on all the aggregared data, using MNI and functional coordinates (extracted by PSC or MSC) method. The objective is reconstruction of masked brain region. where an entire brain region (all electodes in that region) are hidden from input, and reconstructed in the outpus using only electrode coordinates (whether MNI or Functional coordinates extarcted from first 10second of training data). Here 1 second of data is being used as input and prediction length. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277c107",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.distance import pdist, squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce2ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local libraries\n",
    "from src.tools.simulation import *\n",
    "from src.models.CNN_encoder import *\n",
    "from src.models.Functional_transformer import *\n",
    "from src.signal.signal_processing import *\n",
    "from src.pipelines.embedding_data_preparation import *\n",
    "from src.pipelines.transformer_data_preparation import *\n",
    "from src.utils.utils import *\n",
    "from src.training.PSC_training import *\n",
    "from src.training.visualize_embedding import *\n",
    "from src.training.evaluation import *\n",
    "from src.training.Transformer_training import *\n",
    "from src.training.visualize_transformer_predictions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset related libraries (have to replace these with your own dataset loading functions), replace with your own dataset source files\n",
    "import sys\n",
    "import os\n",
    "\n",
    "directory_path = \"D:/Python Projects/ICLR 2026/Dataset_Related\"\n",
    "sys.path.append(os.path.abspath(directory_path))\n",
    "from dataset import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b639202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset related functions and mappings\n",
    "# These functions should be customized for each subject and dataset, here example functions are provided\n",
    "\n",
    "\n",
    "# Define which subjects and sessions to use. subjects are keys and sessions are values\n",
    "# subject_sessions_with_mni = {\n",
    "#     's1': ['p1'], \n",
    "#     's2': ['p1'], \n",
    "#     's3': ['p4', 'p6'], \n",
    "#     's4': ['p1', 'p2'],\n",
    "#     's5': ['p1', 'p2', 'p3', 'p6', 'p7'],\n",
    "#     's6': ['p1', 'p2'], \n",
    "#     's7': ['p1'], \n",
    "#     's8': ['p9'],\n",
    "#     's9': ['p1', 'p2', 'p3'], \n",
    "#     's10': ['p6', 'p7', 'p8', 'p9'],\n",
    "# }\n",
    "\n",
    "# def get_true_region(subject, electrode_name, side, electrode_number, verbose=False):\n",
    "#     \"\"\"\n",
    "#     This function defines the mapping from electrode name and contact number to true brain region for a given subject.\n",
    "#     \"\"\"\n",
    "#     if verbose: print(f\"using default arrangement for {subject}\")\n",
    "#     if 'GPi'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'GPi'\n",
    "#     elif 'VPLa'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VPla'\n",
    "#     elif 'VoSTN'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VO'\n",
    "#     elif 'VoSTN'.lower() in electrode_name.lower() and electrode_number in [1,2,3]:\n",
    "#         return 'STN'\n",
    "#     elif 'STN'.lower() in electrode_name.lower() and electrode_number in [4,5,6]: \n",
    "#         return 'STN'\n",
    "#     elif 'VIM'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VIM'\n",
    "#     elif 'PPN'.lower() in electrode_name.lower() and electrode_number in [1,2,3]:\n",
    "#         return 'PPN'\n",
    "#     elif 'VA'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VA'\n",
    "#     elif 'VoaVop'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VoaVop'\n",
    "#     elif 'VoaVop'.lower() in electrode_name.lower() and electrode_number in [4,5,6]:\n",
    "#         return 'VoaVop'\n",
    "#     else: \n",
    "#         return 'unknown'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5463eb",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8211ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Config ------------ \n",
    "\n",
    "# CNN model paramters: \n",
    "EMBEDDING_DIM = 32\n",
    "\n",
    "# dataset parameters\n",
    "SAVE_DATASET = False  # if True: build & save; if False: load cached full datasets\n",
    "LEN_TRAIN = 0.7\n",
    "LEN_VAL = 0.15\n",
    "LEN_TEST = 0.15\n",
    "MAX_SESSION_LEN_SEC = 10*60 # maximum length of each session in seconds to make sure sessions are not too unbalanced\n",
    "DATASET_WIN_MS = 1000.0\n",
    "DATASET_HOP_MS = 500.0\n",
    "BRAIN_SIDE_EXCLUDE = 'L'  # 'L' or 'R'\n",
    "BRAIN_REGION_EXCLUDE = ['SNR', 'PPN', 'VA']  # list of regions to exclude from training and evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613c550",
   "metadata": {},
   "source": [
    "# Build dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09703569",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "# device = torch.device(\"cpu\")\n",
    "print(f\" Using {device}\")\n",
    "\n",
    "cache_dir = \"data/transformer_datasets\"\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "# choose coordinate system here: can be -> functional_V1, functional_V2, mni\n",
    "# and for control: channel, zero\n",
    "embedding = \"functional_V2\" # \n",
    "\n",
    "if embedding == \"functional_V1\":\n",
    "    # load pretrained functional encoder\n",
    "    models = torch.load(\"D:\\\\Python Projects\\\\ICLR 2026 anonymized\\\\results\\\\multi_subject\\\\PSC_model\\\\full_siamese_model_best.pt\", weights_only=False,map_location=device)  # device can be \"cpu\" or \"cuda\"\n",
    "    models.eval()\n",
    "    encoder= models.encoder\n",
    "    encoder.eval()\n",
    "\n",
    "if embedding == \"functional_V2\":\n",
    "    # load pretrained functional encoder\n",
    "    models = torch.load(\"D:\\\\Python Projects\\\\ICLR 2026 anonymized\\\\results\\\\multi_subject\\\\PSC_model\\\\full_siamese_model_best.pt\", weights_only=False,map_location=device)  # device can be \"cpu\" or \"cuda\"\n",
    "    models.eval()\n",
    "    encoder= models.encoder\n",
    "    encoder.eval()\n",
    "\n",
    "# load mni coordinates\n",
    "mni_coords = pd.read_csv(\"D:/transfer/mni info/electrodes_dataset.csv\")\n",
    "\n",
    "# define empty datasets to be filled\n",
    "train_ds = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "val_ds   = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "test_ds  = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "\n",
    "# determine func_emb_dim from encoder once\n",
    "if embedding == \"functional_V1\" or embedding == \"functional_V2\":\n",
    "    with torch.no_grad():\n",
    "        dummy = torch.randn(1,1,10000, device=device)\n",
    "        func_emb_dim = encoder.embed(dummy).shape[-1]\n",
    "\n",
    "dataPath = \"D:/transfer/micro voluntary dataset/lfs data\"\n",
    "\n",
    "# setup saving locations for datasets\n",
    "dataset_tag = f\"{embedding}_win{int(DATASET_WIN_MS)}_hop{int(DATASET_HOP_MS)}\"\n",
    "full_train_path = os.path.join(cache_dir, f\"FULL_train_{dataset_tag}.pt\")\n",
    "full_val_path   = os.path.join(cache_dir, f\"FULL_val_{dataset_tag}.pt\")\n",
    "full_test_path  = os.path.join(cache_dir, f\"FULL_test_{dataset_tag}.pt\")\n",
    "\n",
    "\n",
    "if SAVE_DATASET:\n",
    "    subject_counter = 0\n",
    "    for isubject in subject_sessions_with_mni:\n",
    "        subject_counter += 1\n",
    "        for iperiod in subject_sessions_with_mni[isubject]:\n",
    "            session_signals_train = {}\n",
    "            session_signals_val = {}\n",
    "            session_signals_test = {}\n",
    "            session_embeds  = {}     # ch -> (F,)\n",
    "            session_regions = {}    # {channel: \"GPi\"/\"STN\"/...} true brain region labels\n",
    "            fs_session = None\n",
    "            channel_counter = -1\n",
    "            \n",
    "            path = os.path.join(dataPath, isubject, iperiod)\n",
    "\n",
    "            # load microelectrode labels\n",
    "            try:\n",
    "                microelectrodes = load_micro_labels(os.path.join(path, \"microLabels.mat\"))\n",
    "            except:\n",
    "                mat_contents = loadmat(os.path.join(path, \"microLabels.mat\"))\n",
    "                micro_labels = mat_contents['microLabels']\n",
    "                microelectrodes = [str(label[0]) if isinstance(label, np.ndarray) else str(label)\n",
    "                                    for label in micro_labels.squeeze()]\n",
    "\n",
    "            # load microelectrode signals\n",
    "            for microelectrode in microelectrodes:\n",
    "                region, side, electrode = parse_label(microelectrode)\n",
    "                true_region = get_true_region(isubject, region, side, electrode) \n",
    "                if true_region == 'unknown' or side==BRAIN_SIDE_EXCLUDE or true_region in BRAIN_REGION_EXCLUDE:\n",
    "                    continue  # skip unlabeled channels\n",
    "                true_region = true_region + side\n",
    "                channel_counter = channel_counter + 1\n",
    "                # load file\n",
    "                mat_path = os.path.join(path, microelectrode + \".mat\")\n",
    "                try:\n",
    "                    with h5py.File(mat_path, \"r\") as f:\n",
    "                        raw_signal = np.array(f[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(f[\"fs\"]).squeeze())\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"Error loading {microelectrode} from {mat_path}. Skipping this channel.\")\n",
    "                    continue\n",
    "                except (OSError, KeyError):\n",
    "                    try:\n",
    "                        mat = scipy.io.loadmat(mat_path)\n",
    "                        raw_signal = np.array(mat[\"data\"]).squeeze()\n",
    "                        fs = int(np.array(mat[\"fs\"]).squeeze())\n",
    "                    except:\n",
    "                        print(f\"Error loading {microelectrode} from {mat_path}. Skipping this channel.\")\n",
    "                        continue\n",
    "\n",
    "                if fs_session is None: fs_session = fs\n",
    "\n",
    "                # Remove big 60Hz artifacts\n",
    "                filtered_signal = notch_filter(raw_signal,fs)\n",
    "\n",
    "                # Normalize session recording\n",
    "                normalized_signal = normalize_signal(filtered_signal)\n",
    "\n",
    "                # Apply notch filters at 60Hz and its harmonics\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=60)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=120)\n",
    "                normalized_signal = notch_filter(normalized_signal,fs,freq=180)\n",
    "\n",
    "                # Apply lowpass filter\n",
    "                signal = lowpass_filter(normalized_signal, cutoff=50, fs=fs, order=2)\n",
    "\n",
    "                # Truncate or pad signal to MAX_SESSION_LEN_SEC\n",
    "                if len(signal)> MAX_SESSION_LEN_SEC*fs:\n",
    "                    signal = signal[:MAX_SESSION_LEN_SEC*fs]\n",
    "\n",
    "                # split into train/val/test\n",
    "                n =len(signal)\n",
    "                train_end = int(n * LEN_TRAIN)\n",
    "                val_end = int(n * (LEN_TRAIN + LEN_VAL))\n",
    "\n",
    "                # grab the appropriate coordinate system \n",
    "                if embedding == \"functional_V1\":\n",
    "                    segment = signal[0:int(fs*10)]\n",
    "                    x = torch.tensor(segment, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, T)\n",
    "                    embedding_vector = encoder.embed(x).detach().cpu().numpy().squeeze()\n",
    "\n",
    "                elif embedding == \"functional_V2\":\n",
    "                    segment = signal[0:int(fs*10)]\n",
    "                    x = torch.tensor(segment, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1, 1, T)\n",
    "                    embedding_vector = encoder.embed(x).detach().cpu().numpy().squeeze()\n",
    "\n",
    "                elif embedding == \"mni\":\n",
    "                    \n",
    "                    _region_val = str(region).strip().casefold()\n",
    "\n",
    "                    # correct for regin name mismatches\n",
    "                    if isubject == SUBJECT1 and (_region_val ==\"voavop\"): electrode+=3\n",
    "                    if isubject == SUBJECT1 and (_region_val ==\"voavop\" or _region_val ==\"stn\"): _region_val = \"vostn\"\n",
    "                    if isubject == SUBJECT10 and (_region_val ==\"vostnsnr\"): _region_val = \"vostn\"\n",
    "                    \n",
    "                    # grab mni coordinates\n",
    "                    _side_val   = str(side).strip().casefold()\n",
    "                    _subject_val = f\"{isubject}_{iperiod}\".strip()  # <- if you want dynamic subject; else keep your fixed value\n",
    "                    _region_mask  = mni_coords[\"region\"].astype(str).str.strip().str.casefold().eq(_region_val)\n",
    "                    _side_mask    = mni_coords[\"side\"].astype(str).str.strip().str.casefold().eq(_side_val)\n",
    "                    _number_mask  = pd.to_numeric(mni_coords[\"number\"], errors=\"coerce\").eq(electrode)\n",
    "                    _micro_mask   = mni_coords[\"scale\"].astype(str).str.strip().str.casefold().str.rstrip('s').eq(\"micro\")\n",
    "                    _subject_mask = mni_coords[\"subject\"].astype(str).str.strip().eq(isubject)  # or use _subject_val\n",
    "\n",
    "                    row = mni_coords[_region_mask & _micro_mask & _subject_mask & _side_mask & _number_mask].copy()\n",
    "                    embedding_vector = np.array([row[\"x\"], row[\"y\"], row[\"z\"]], dtype=float).squeeze()\n",
    "                    print(\"mni coordinates: \", embedding_vector)\n",
    "\n",
    "                    # Fallback if no match or multiple matches\n",
    "                    if len(row) == 0:\n",
    "                        # fallback to zeros or handle as you prefer\n",
    "                        print(\"did not find MNI coordinates: \", _region_val)\n",
    "                        embedding_vector = np.zeros(3, dtype=float)\n",
    "                    else:\n",
    "                        # if multiple, take the first\n",
    "                        print(\"found multiple MNI coordinates\")\n",
    "                        r = row.iloc[0]\n",
    "                        embedding_vector = np.array([r[\"x\"], r[\"y\"], r[\"z\"]], dtype=float)\n",
    "\n",
    "                elif embedding == \"channel\":\n",
    "                    embedding_dim = EMBEDDING_DIM\n",
    "                    embedding_vector = np.zeros(embedding_dim) \n",
    "                    embedding_vector[channel_counter]=1\n",
    "\n",
    "                elif embedding == \"zero\":\n",
    "                    embedding_dim = EMBEDDING_DIM\n",
    "                    embedding_vector = np.zeros(embedding_dim) \n",
    "                \n",
    "                # stash per-session\n",
    "                session_signals_train[microelectrode] = signal[:train_end].astype(np.float32)\n",
    "                session_signals_val[microelectrode] = signal[train_end:val_end].astype(np.float32)\n",
    "                session_signals_test[microelectrode] = signal[val_end:].astype(np.float32)\n",
    "\n",
    "                session_embeds[microelectrode]  = embedding_vector.astype(np.float32)\n",
    "                session_regions[microelectrode] = true_region \n",
    "\n",
    "\n",
    "            # 1) add to FULL multi-subject datasets\n",
    "            added = train_ds.add_session(\n",
    "                session_path=path,\n",
    "                fs=fs_session,\n",
    "                signals=session_signals_train,\n",
    "                embeds=session_embeds,\n",
    "                region_map=session_regions\n",
    "            )\n",
    "\n",
    "            val_added = val_ds.add_session(\n",
    "                session_path=path,\n",
    "                fs=fs_session,\n",
    "                signals=session_signals_val,\n",
    "                embeds=session_embeds,\n",
    "                region_map=session_regions\n",
    "            )\n",
    "\n",
    "            testadded = test_ds.add_session(\n",
    "                session_path=path,\n",
    "                fs=fs_session,\n",
    "                signals=session_signals_test,\n",
    "                embeds=session_embeds,\n",
    "                region_map=session_regions\n",
    "            )\n",
    "            print(f\"  -> MRCP windows added: {added} from S{subject_counter}/{iperiod}\")\n",
    "\n",
    "            # 2) also save per-subject-period datasets (train/val/test)\n",
    "            sp_train_ds = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "            sp_val_ds   = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "            sp_test_ds  = MRCPStreamDataset(window_ms=DATASET_WIN_MS, hop_ms=DATASET_HOP_MS)\n",
    "\n",
    "            _ = sp_train_ds.add_session(\n",
    "                session_path=path, fs=fs_session,\n",
    "                signals=session_signals_train, embeds=session_embeds, region_map=session_regions\n",
    "            )\n",
    "            _ = sp_val_ds.add_session(\n",
    "                session_path=path, fs=fs_session,\n",
    "                signals=session_signals_val, embeds=session_embeds, region_map=session_regions\n",
    "            )\n",
    "            _ = sp_test_ds.add_session(\n",
    "                session_path=path, fs=fs_session,\n",
    "                signals=session_signals_test, embeds=session_embeds, region_map=session_regions\n",
    "            )\n",
    "\n",
    "            sp_prefix = f\"{isubject}_{iperiod}_{dataset_tag}\"\n",
    "            torch.save(sp_train_ds, os.path.join(cache_dir, f\"{sp_prefix}_train.pt\"))\n",
    "            torch.save(sp_val_ds,   os.path.join(cache_dir, f\"{sp_prefix}_val.pt\"))\n",
    "            torch.save(sp_test_ds,  os.path.join(cache_dir, f\"{sp_prefix}_test.pt\"))\n",
    "            print(f\"  -> Saved per-session datasets: S{subject_counter}_{iperiod}_{dataset_tag}_[train|val|test].pt\")\n",
    "\n",
    "    # After finishing all subjects/periods, save the FULL multi-subject datasets\n",
    "    torch.save(train_ds, full_train_path)\n",
    "    torch.save(val_ds,   full_val_path)\n",
    "    torch.save(test_ds,  full_test_path)\n",
    "    print(f\"[CACHE] Saved FULL datasets to:\\n  {full_train_path}\\n  {full_val_path}\\n  {full_test_path}\")\n",
    "else:\n",
    "    # Load prebuilt FULL datasets (skips the subject/period loop)\n",
    "    if not (os.path.exists(full_train_path) and os.path.exists(full_val_path) and os.path.exists(full_test_path)):\n",
    "        raise FileNotFoundError(\n",
    "            \"Cached FULL datasets not found. Set SAVE_DATASET=True once to build and cache them.\\n\"\n",
    "            f\"Expected:\\n  {full_train_path}\\n  {full_val_path}\\n  {full_test_path}\"\n",
    "        )\n",
    "    train_ds = torch.load(full_train_path, map_location=device)\n",
    "    val_ds   = torch.load(full_val_path,   map_location=device)\n",
    "    test_ds  = torch.load(full_test_path,  map_location=device)\n",
    "    print(f\"[CACHE] Loaded FULL datasets from cache: tag={dataset_tag}\")\n",
    "\n",
    "\n",
    "# (optional) see how regions were mapped to ids\n",
    "print(\"Region vocab:\", train_ds.region_vocab)        \n",
    "print(f\"Total training windows: {len(train_ds)} samples\")\n",
    "print(f\"Total validating windows: {len(val_ds)} samples\")\n",
    "print(f\"Total testing windows: {len(test_ds)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23808695",
   "metadata": {},
   "source": [
    "# Configure training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer parameters\n",
    "D_MODEL = 128 # model width\n",
    "PATCH_MS = 25.0 # patch size in ms\n",
    "TARGET_FS = 1000  # target sampling rate after patching\n",
    "NHEAD = 4\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "FEEDFORWARD_DIM = 384\n",
    "\n",
    "# training parameters\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 150\n",
    "DROPOUT = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8128d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\" Using {device}\")\n",
    "try:\n",
    "    func_emb_dim = next(iter(session_embeds.values())).shape[0] \n",
    "    fs_common = fs_session \n",
    "except:\n",
    "    func_emb_dim = EMBEDDING_DIM  # default value\n",
    "    fs_common = 1000  \n",
    "\n",
    "# --- pick which region(s) to exclude (e.g., all names starting with \"VO\") ---\n",
    "excluded_ids = compute_excluded_region_ids(train_ds.region_vocab, predicate=lambda name: str(name).upper().startswith(\"VO\"))\n",
    "print(\"Excluded region ids:\", excluded_ids)\n",
    "\n",
    "# --- loaders ---\n",
    "Kmax = None  # no limit on max number of query channels\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0,\n",
    "    collate_fn=lambda b: collate_region_exclude_train_multi(b, device, excluded_ids, Kmax=Kmax)\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,\n",
    "    collate_fn=lambda b: collate_region_exclude_eval_multi(b, device, excluded_ids, Kmax=Kmax, order=\"maxvar\")\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0,\n",
    "    collate_fn=lambda b: collate_region_exclude_eval_multi(b, device, excluded_ids, Kmax=Kmax, order=\"maxvar\")\n",
    ")\n",
    "\n",
    "model = QueryReconTransformerPruned(\n",
    "    func_emb_dim=func_emb_dim, fs=fs_common,\n",
    "    d_model=D_MODEL, nhead=NHEAD, num_enc_layers=NUM_ENCODER_LAYERS, num_dec_layers=NUM_DECODER_LAYERS,\n",
    "    patch_ms=PATCH_MS, stride_ms=None, dim_ff=FEEDFORWARD_DIM, dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# setup optimizer with different lrs for head and body\n",
    "params = []\n",
    "for n,p in model.named_parameters():\n",
    "    if not p.requires_grad: continue\n",
    "    params.append({\"params\":[p], \"lr\":2e-4 if not n.startswith(\"head\") else 3e-4,\n",
    "                   \"weight_decay\":1e-4 if needs_wd(n,p) else 0.0})\n",
    "opt = torch.optim.AdamW(params, betas=(0.9,0.99), eps=1e-8)\n",
    "\n",
    "# print model parameters\n",
    "count_parameters(model)\n",
    "print(\"embedding type: (\", embedding,\") embedding size:\", func_emb_dim)\n",
    "\n",
    "# visualize query example for control before training\n",
    "plot_query_example_region_exclude_multi(model, val_loader, fs=fs_common, device=device, sample_idx=0, max_k=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c30e88",
   "metadata": {},
   "source": [
    "# Train transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = nn.MSELoss()\n",
    "results_dir = \"results/transformer_training_\" + embedding\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "print(\"training...\")\n",
    "best_val_nmse = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # ================== Train ==================\n",
    "    model.train()\n",
    "    tr_sum = tr_n = 0.0\n",
    "    for batch in train_loader:\n",
    "        # guard against empty/short\n",
    "        if batch[0].numel() == 0 or batch[0].shape[-1] < model.patch_len:\n",
    "            continue\n",
    "\n",
    "        # Unpack multi-target batch:\n",
    "        waves_src, fembs_src, ch_counts, pad_mask, fembs_tgt, tgt_pad_mask, y_true = batch\n",
    "\n",
    "        # Forward: (B, K, Tm)\n",
    "        y_hat = model(waves_src, fembs_src, pad_mask, fembs_tgt, tgt_pad_mask)\n",
    "        Tm = y_hat.shape[-1]\n",
    "\n",
    "        # Compute training loss over valid targets\n",
    "        y_hat_v, y_true_v = flatten_valid(y_hat, y_true[:, :, :Tm], tgt_pad_mask)\n",
    "        if y_hat_v is None:\n",
    "            continue\n",
    "\n",
    "        loss_mse  = torch.nn.functional.mse_loss(y_hat_v, y_true_v)\n",
    "        loss_corr = corr_loss(y_hat_v, y_true_v)  # existing loss (1 - r)\n",
    "        loss = loss_mse + 0.05 * loss_corr\n",
    "\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "\n",
    "        bs = waves_src.size(0)\n",
    "        tr_sum += loss.item() * bs\n",
    "        tr_n   += bs\n",
    "\n",
    "    # ================== Validation ==================\n",
    "    model.eval()\n",
    "    va_sum = va_n = 0.0\n",
    "    val_nmse_list, val_nrmse_list, val_r_list = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if batch[0].numel() == 0 or batch[0].shape[-1] < model.patch_len:\n",
    "                continue\n",
    "            waves_src, fembs_src, ch_counts, pad_mask, fembs_tgt, tgt_pad_mask, y_true = batch\n",
    "            y_hat = model(waves_src, fembs_src, pad_mask, fembs_tgt, tgt_pad_mask)  # (B,K,Tm)\n",
    "            Tm = y_hat.shape[-1]\n",
    "\n",
    "            # Loss for logging (same as train)\n",
    "            y_hat_v, y_true_v = flatten_valid(y_hat, y_true[:, :, :Tm], tgt_pad_mask)\n",
    "            if y_hat_v is None:\n",
    "                continue\n",
    "            loss_mse  = torch.nn.functional.mse_loss(y_hat_v, y_true_v)\n",
    "            loss_corr = corr_loss(y_hat_v, y_true_v)\n",
    "            loss = loss_mse + 0.05 * loss_corr\n",
    "\n",
    "            bs = waves_src.size(0)\n",
    "            va_sum += loss.item() * bs\n",
    "            va_n   += bs\n",
    "\n",
    "            # Metrics: NMSE / NRMSE / r across valid targets\n",
    "            nmse_mean, nrmse_mean, r_mean = nmse_nrmse_r(y_hat_v, y_true_v)\n",
    "            val_nmse_list.append(nmse_mean)\n",
    "            val_nrmse_list.append(nrmse_mean)\n",
    "            val_r_list.append(r_mean)\n",
    "\n",
    "    # Aggregate validation metrics\n",
    "    val_nmse = float(np.mean(val_nmse_list)) if len(val_nmse_list) else float(\"inf\")\n",
    "    val_nrmse = float(np.mean(val_nrmse_list)) if len(val_nrmse_list) else float(\"inf\")\n",
    "    val_r = float(np.mean(val_r_list)) if len(val_r_list) else float(\"-inf\")\n",
    "\n",
    "    tr_loss = tr_sum / max(1.0, tr_n)\n",
    "    va_loss = va_sum / max(1.0, va_n)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | train_loss={tr_loss:.4f} | val_loss={va_loss:.4f} | \"\n",
    "          f\"val_NMSE={val_nmse:.4f} | val_NRMSE={val_nrmse:.4f} | val_r={val_r:.4f}\")\n",
    "\n",
    "    # Save best-by-val NMSE\n",
    "    if val_nmse < best_val_nmse:\n",
    "        best_val_nmse = val_nmse\n",
    "        best_path = os.path.join(results_dir, \"model_best_by_val_nmse.pt\")\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optimizer_state\": opt.state_dict(),\n",
    "            \"val_nmse\": val_nmse,\n",
    "            \"val_nrmse\": val_nrmse,\n",
    "            \"val_r\": val_r,\n",
    "            \"val_loss\": va_loss,\n",
    "        }, best_path)\n",
    "        best_path = os.path.join(results_dir, \"model_best_by_val_nmse_full.pt\")\n",
    "        torch.save(model, best_path)\n",
    "        print(f\"  ↳ Saved new BEST checkpoint (val_NMSE={val_nmse:.4f}) → {best_path}\")\n",
    "\n",
    "    # (optional) Always save last\n",
    "    last_path = os.path.join(results_dir, \"model_last.pt\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optimizer_state\": opt.state_dict(),\n",
    "        \"val_nmse\": val_nmse,\n",
    "        \"val_nrmse\": val_nrmse,\n",
    "        \"val_r\": val_r,\n",
    "        \"val_loss\": va_loss,\n",
    "    }, last_path)\n",
    "    last_path = os.path.join(results_dir, \"model_last_full.pt\")\n",
    "    torch.save(model, last_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c155e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_query_example_region_exclude_multi(model, test_loader, fs=fs_common, device=device, sample_idx=1, max_k=None,random_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f83268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anonymized-ICLR2026.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
